{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50113392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def sentence_tokenize(text):\n",
    "    return [s.strip() for s in re.split(r'(?<=[.!?])\\s+', str(text).strip()) if s]\n",
    "\n",
    "def load_and_process_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    processed = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        claim = row['Statement']\n",
    "        context = row['Context']\n",
    "        evidence = row['Evidence']\n",
    "        label = int(row['labels'])\n",
    "\n",
    "        sentences = sentence_tokenize(context)\n",
    "        rationale_indices = [\n",
    "            i for i, s in enumerate(sentences)\n",
    "            if evidence.strip() in s or s in evidence.strip()\n",
    "        ]\n",
    "\n",
    "        processed.append({\n",
    "            \"claim\": claim,\n",
    "            \"evidences\": sentences,\n",
    "            \"label\": label,\n",
    "            \"rationale_indices\": rationale_indices\n",
    "        })\n",
    "\n",
    "    return processed\n",
    "\n",
    "train_data = load_and_process_csv(\"./data/train_clean.csv\")\n",
    "test_data = load_and_process_csv(\"./data/test_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beeea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "class IBModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=768):\n",
    "        super().__init__()\n",
    "        self.encoder = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.mask_head = nn.Linear(hidden_dim, 1)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, claim, sentences):\n",
    "        inputs = [claim + \" [SEP] \" + s for s in sentences]\n",
    "        enc = tokenizer(inputs, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = self.encoder(input_ids=enc['input_ids'].to(device),\n",
    "                                attention_mask=enc['attention_mask'].to(device))\n",
    "\n",
    "        cls_embeddings = out.last_hidden_state[:, 0, :]  # [num_sentences, hidden_dim]\n",
    "        mask_logits = self.mask_head(cls_embeddings).squeeze(-1)  # [num_sentences]\n",
    "        mask_probs = torch.sigmoid(mask_logits)\n",
    "\n",
    "        masked_embeds = cls_embeddings * mask_probs.unsqueeze(1)\n",
    "        pooled = masked_embeds.sum(dim=0) / (mask_probs.sum() + 1e-6)\n",
    "\n",
    "        logits = self.classifier(pooled)\n",
    "        return logits, mask_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a946e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, label, masks, lambda_sparsity=1.0):\n",
    "    ce_loss = F.cross_entropy(logits.unsqueeze(0), torch.tensor([label]).to(logits.device))\n",
    "    sparsity = masks.mean()\n",
    "    return ce_loss + lambda_sparsity * sparsity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ccb6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2750.6581\n",
      "Epoch 2, Loss: 2434.0114\n",
      "Epoch 3, Loss: 2377.1775\n",
      "Epoch 4, Loss: 2364.2100\n",
      "Epoch 5, Loss: 2359.8566\n",
      "Epoch 6, Loss: 2357.6049\n",
      "Epoch 7, Loss: 2356.3872\n",
      "Epoch 8, Loss: 2355.3495\n",
      "Epoch 9, Loss: 2354.8925\n",
      "Epoch 10, Loss: 2353.8180\n"
     ]
    }
   ],
   "source": [
    "model = IBModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for sample in train_data:\n",
    "        claim = sample[\"claim\"]\n",
    "        sentences = sample[\"evidences\"]\n",
    "        label = sample[\"label\"]\n",
    "\n",
    "        logits, masks = model(claim, sentences)\n",
    "        loss = compute_loss(logits, label, masks, lambda_sparsity=0.5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8237dd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim Classification:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   SUPPORTED       0.55      0.74      0.63       508\n",
      "     REFUTED       0.55      0.35      0.42       468\n",
      "\n",
      "    accuracy                           0.55       976\n",
      "   macro avg       0.55      0.54      0.53       976\n",
      "weighted avg       0.55      0.55      0.53       976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in test_data:\n",
    "        claim = sample[\"claim\"]\n",
    "        sentences = sample[\"evidences\"]\n",
    "        label = sample[\"label\"]\n",
    "\n",
    "        logits, _ = model(claim, sentences)\n",
    "        pred = torch.argmax(logits).item()\n",
    "\n",
    "        all_preds.append(pred)\n",
    "        all_labels.append(label)\n",
    "\n",
    "print(\"Claim Classification:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"SUPPORTED\", \"REFUTED\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1857025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ib_rationale(model, dataset, threshold=0.3):\n",
    "    model.eval()\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_f1s = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sample in dataset:\n",
    "            claim = sample[\"claim\"]\n",
    "            sentences = sample[\"evidences\"]\n",
    "            gold = sample[\"rationale_indices\"]\n",
    "\n",
    "            _, scores = model(claim, sentences)\n",
    "            pred = [i for i, s in enumerate(scores.cpu()) if s > threshold]\n",
    "\n",
    "            true_set = set(gold)\n",
    "            pred_set = set(pred)\n",
    "\n",
    "            if not true_set and not pred_set:\n",
    "                precision = recall = f1 = 1.0\n",
    "            elif not pred_set:\n",
    "                precision = recall = f1 = 0.0\n",
    "            else:\n",
    "                tp = len(true_set & pred_set)\n",
    "                precision = tp / len(pred_set) if pred_set else 0.0\n",
    "                recall = tp / len(true_set) if true_set else 0.0\n",
    "                f1 = 2 * precision * recall / (precision + recall + 1e-8) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "            all_precisions.append(precision)\n",
    "            all_recalls.append(recall)\n",
    "            all_f1s.append(f1)\n",
    "\n",
    "    print(\"Rationale Extraction Quality:\")\n",
    "    print(f\"Precision: {sum(all_precisions)/len(all_precisions):.3f}\")\n",
    "    print(f\"Recall:    {sum(all_recalls)/len(all_recalls):.3f}\")\n",
    "    print(f\"F1-score:  {sum(all_f1s)/len(all_f1s):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2059f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale Extraction Quality:\n",
      "Precision: 0.316\n",
      "Recall:    0.316\n",
      "F1-score:  0.316\n"
     ]
    }
   ],
   "source": [
    "evaluate_ib_rationale(model, test_data, threshold=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669f0037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale Extraction Quality:\n",
      "Precision: 0.316\n",
      "Recall:    0.316\n",
      "F1-score:  0.316\n"
     ]
    }
   ],
   "source": [
    "evaluate_ib_rationale(model, test_data, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30093d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale Extraction Quality:\n",
      "Precision: 0.316\n",
      "Recall:    0.316\n",
      "F1-score:  0.316\n"
     ]
    }
   ],
   "source": [
    "evaluate_ib_rationale(model, test_data, threshold=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3e74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model/ib_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0cc530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = IBModel().to(device)\n",
    "# model.load_state_dict(torch.load(\"ib_model.pt\", map_location=device))\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
